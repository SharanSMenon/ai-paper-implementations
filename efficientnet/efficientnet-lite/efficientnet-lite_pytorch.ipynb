{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd75bfa0-8ff3-4a56-a222-0a73068bb4ff",
   "metadata": {},
   "source": [
    "# EfficientNet Lite in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e55ee58-7dcc-485b-91ec-5329b248bf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import math\n",
    "import os\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09d41e73-3720-4f39-916b-7602e40fedaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(in_channels, out_channels, kernel_size=3, \n",
    "               stride=1, padding=0, groups=1,\n",
    "               bias=False, bn=True, act = True):\n",
    "    layers = [\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size, stride=stride, \n",
    "                  padding=padding, groups=groups, bias=bias),\n",
    "        nn.BatchNorm2d(out_channels) if bn else nn.Identity(),\n",
    "        nn.ReLU6() if act else nn.Identity()\n",
    "    ]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df21a513-e747-4d9f-a2ae-4378ba6e3c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    \"\"\"\n",
    "    An implementation of the Inverted Residual from the MobileNet paper.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_in, n_out, expansion, kernel_size=3, stride=1, dropout=0.1):\n",
    "        super(MBConv, self).__init__()\n",
    "        self.skip_connection = (n_in == n_out) and (stride == 1)\n",
    "        padding = (kernel_size-1)//2\n",
    "        expanded = expansion*n_in\n",
    "        \n",
    "        self.expand_pw = nn.Identity() if expansion == 1 else conv_block(n_in, expanded, kernel_size=1)\n",
    "        self.depthwise = conv_block(expanded, expanded, kernel_size=kernel_size, \n",
    "                                    stride=stride, padding=padding, groups=expanded)\n",
    "        self.reduce_pw = conv_block(expanded, n_out, kernel_size=1, act=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.expand_pw(x)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.reduce_pw(x)\n",
    "        if self.skip_connection:\n",
    "            x = self.dropout(x)\n",
    "            x = x + residual\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "777c11c8-e042-4b52-ba2a-a57146e225d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbconv1(n_in, n_out, kernel_size=3, stride=1, dropout=0.2):\n",
    "    return MBConv(n_in, n_out, 1, kernel_size=kernel_size, stride=stride, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "115dc875-517d-4cf5-9441-0344f144b69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mbconv6(n_in, n_out, kernel_size=3, stride=1, r=24, dropout=0.2):\n",
    "    return MBConv(n_in, n_out, 6, kernel_size=kernel_size, stride=stride, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90de185f-a60f-4bd3-a22f-4bb090d22538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stage(n_in, n_out, num_layers, layer=mbconv6, \n",
    "                 kernel_size=3, stride=1, dropout=0.2):\n",
    "    \"\"\"\n",
    "    A utility for creating a single EfficientNet stage.\n",
    "    \"\"\"\n",
    "    layers = [layer(n_in, n_out, kernel_size=kernel_size,\n",
    "                       stride=stride, dropout=dropout)]\n",
    "    layers += [layer(n_out, n_out, kernel_size=kernel_size,\n",
    "                        dropout=dropout) for _ in range(num_layers-1)]\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ad5a73-ed3d-4cfa-849a-d292782cd6c4",
   "metadata": {},
   "source": [
    "EfficientNet Base structure\n",
    "\n",
    "| Stage (i) | Layer     | Resolution | Channels | Layers |\n",
    "|-----------|-----------|------------|----------|--------|\n",
    "| 1         | `mbconv1` | 224 x 224  | 32       | 1      |\n",
    "| 2         | `mbconv6` | 112 x 112  | 16       | 1      |\n",
    "| 3         | `mbconv6` | 112 x 112  | 24       | 2      |\n",
    "| 4         | `mbconv6` | 56 x 56    | 40       | 2      |\n",
    "| 5         | `mbconv6` | 28 x 28    | 80       | 3      |\n",
    "| 6         | `mbconv6` | 14 x 14    | 112      | 3      |\n",
    "| 7         | `mbconv6` | 14 x 14    | 192      | 4      |\n",
    "| 8         | `mbconv6` | 7 x 7      | 320      | 1      |\n",
    "| 9         | `mbconv6` | 7 x 7      | 1080     | 1      |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83b2baa2-4923-4a05-8f33-9429214baa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Obtained from Paper ###\n",
    "widths = [32, 16, 24, 40, 80, 112, 192, 320, 1280]\n",
    "depths = [1, 2, 2, 3, 3, 4, 1]\n",
    "kernel_sizes = [3, 3, 5, 3, 5, 5, 3]\n",
    "strides = [1, 2, 2, 2, 1, 2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75969bd4-77e4-4d23-aeb3-8894d504fb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_width(w, w_factor):\n",
    "    \"\"\"\n",
    "    This function scales the width.\n",
    "    \"\"\"\n",
    "    w *= w_factor\n",
    "    new_w = (int(w+4) // 8) * 8\n",
    "    new_w = max(8, new_w)\n",
    "    if new_w < 0.9*w:\n",
    "        new_w += 8\n",
    "    return int(new_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22099a0a-2579-4268-ac29-52db221b5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_scaler(w_factor=1, d_factor=1):\n",
    "    \"\"\"\n",
    "    Efficientnet scaler function as defined in the paper.\n",
    "    \"\"\"\n",
    "    scaled_widths = [scale_width(w, w_factor) for w in widths]\n",
    "    scaled_widths[0] = 32\n",
    "    scaled_widths[-1] = 1280\n",
    "    scaled_depths = [math.ceil(d_factor*d) for d in depths]\n",
    "    scaled_depths[0] = scaled_depths[-1] = 1\n",
    "    return scaled_widths, scaled_depths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08cdce48-2c2e-4bc7-bbd0-c8ab6bc02113",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Generic EfficientNet class. This model is easily customizable for you can easily swap out the classification head \n",
    "    for something more complex.\n",
    "    \"\"\"\n",
    "    def __init__(self, w_factor=1, d_factor=1, n_classes=1000):\n",
    "        super(EfficientNet, self).__init__()\n",
    "        scaled_widths, scaled_depths = efficientnet_scaler(w_factor=w_factor, d_factor=d_factor)\n",
    "    \n",
    "        self.stem = conv_block(3, scaled_widths[0], stride=2, padding=1)\n",
    "        stages = [\n",
    "            create_stage(scaled_widths[i], scaled_widths[i+1], scaled_depths[i], layer= mbconv1 if i==0 else mbconv6, \n",
    "                         kernel_size=kernel_sizes[i], stride=strides[i], dropout=0.2) for i in range(7)\n",
    "        ]\n",
    "        self.stages = nn.Sequential(*stages)\n",
    "        self.pre = conv_block(scaled_widths[-2], scaled_widths[-1], kernel_size=1)\n",
    "        self.pool_flatten = nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten())\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(scaled_widths[-1], n_classes)\n",
    "        )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.stages(x)\n",
    "        x = self.pre(x)\n",
    "        x = self.pool_flatten(x)\n",
    "        x = self.head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdf18010-72ee-44df-84b4-e330eb281c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EfficientNetSequential( w_factor=1, d_factor=1, n_classes=1000, dropout=0.2):\n",
    "    \"\"\"\n",
    "    Another EfficientNet Builder. Is basically the same as the class above. However, it is harder to customize since you\n",
    "    \n",
    "    \"\"\"\n",
    "    scaled_widths, scaled_depths = efficientnet_scaler(w_factor=w_factor, d_factor=d_factor)\n",
    "    layers = [\n",
    "        conv_block(3, scaled_widths[0], stride=2, padding=1)\n",
    "    ]\n",
    "    stages = [\n",
    "            create_stage(scaled_widths[i], scaled_widths[i+1], scaled_depths[i], layer= mbconv1 if i==0 else mbconv6, \n",
    "                         kernel_size=kernel_sizes[i], stride=strides[i], dropout=dropout) for i in range(7)\n",
    "    ]\n",
    "    layers = layers + stages\n",
    "    layers.append(conv_block(scaled_widths[-2], scaled_widths[-1], kernel_size=1))\n",
    "    layers.append(nn.Sequential(nn.AdaptiveAvgPool2d(1), nn.Flatten()))\n",
    "    layers.append(nn.Sequential(nn.Linear(scaled_widths[-1], n_classes)))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9fe3126b-d63a-4fdb-b081-698f07092cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_lite0(n_classes=1000, builder = EfficientNet):\n",
    "    return builder(n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "335c91f7-60a7-4397-b2ea-ba9755e0a259",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_lite1(n_classes=1000, builder = EfficientNet):\n",
    "    return builder(1, 1.1, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a9ae8295-66e0-4788-861e-af81cf33e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_lite2(n_classes=1000, builder = EfficientNet):\n",
    "    return builder(1.1, 1.2, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "227832fc-48b7-4c75-ae40-86213f008c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_lite3(n_classes=1000, builder = EfficientNet):\n",
    "    return builder(1.2, 1.4, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdfaff84-9f4a-4ba6-94f5-aa07ab81d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnet_lite4(n_classes=1000, builder = EfficientNet):\n",
    "    return builder(1.4, 1.8, n_classes=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ddc4822-db1f-4286-bd7f-f8a131ed6af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_sizes = [224, 240, 260, 280, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce69f255-c00b-4dc3-a044-37f1cc1be178",
   "metadata": {},
   "outputs": [],
   "source": [
    "lite0 = efficientnet_lite0()\n",
    "lite1 = efficientnet_lite1(builder=EfficientNetSequential)\n",
    "lite2 = efficientnet_lite2()\n",
    "lite3 = efficientnet_lite3(builder=EfficientNetSequential)\n",
    "lite4 = efficientnet_lite4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91f2d0f0-d579-448a-b75d-4ec32c6fb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lite0, lite1, lite2, lite3, lite4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "15858249-5a11-4e41-afe5-bd071b6c1417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1000]), torch.Size([1, 1000]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lite_0_inp = torch.randn(1, 3, img_sizes[0], img_sizes[0])\n",
    "lite_1_inp = torch.randn(1, 3, img_sizes[1], img_sizes[1])\n",
    "lite0(lite_0_inp).shape, lite1(lite_1_inp).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "43caafea-ef4e-4dd2-bff4-e0268b84a68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a79c046d-882f-439b-9b60-9c0997baebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size (MB): 18.875633\n",
      "Size (MB): 22.006461\n",
      "Size (MB): 24.729981\n",
      "Size (MB): 33.237073\n",
      "Size (MB): 52.660985\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print_size_of_model(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c3259af2-9648-4788-849e-d9878b6d90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fmat(n):\n",
    "    return \"{:.2f}M\".format(n / 1_000_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "32a21dc3-3bd4-48d6-902f-b0fd22fbf261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params(model, f=True):\n",
    "    s = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return fmat(s) if f else s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "994369d9-3be0-4896-838a-b5ff7b94c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.65M\n",
      "5.42M\n",
      "6.09M\n",
      "8.20M\n",
      "13.01M\n"
     ]
    }
   ],
   "source": [
    "for m in models:\n",
    "    print(params(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d8f7b707-8cc1-43f7-be6a-30bd865bc6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Sequential                               --                        --\n",
       "==========================================================================================\n",
       "Total params: 8,197,096\n",
       "Trainable params: 8,197,096\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.38\n",
       "==========================================================================================\n",
       "Input size (MB): 0.94\n",
       "Forward/backward pass size (MB): 303.76\n",
       "Params size (MB): 32.79\n",
       "Estimated Total Size (MB): 337.49\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 3\n",
    "summary(models[i], (1, 3, img_sizes[i], img_sizes[i]), depth=0) # pick a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73376562-2f1f-4e1a-a962-5bce8fdc1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ce516c23-2592-4827-b824-2ff855310261",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = timm.create_model('tf_efficientnet_lite4', pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7a1eb9e1-0990-407a-9f99-f941fcff93e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "EfficientNet                                  --                        --\n",
       "├─Conv2dSame: 1-1                             [1, 32, 140, 140]         864\n",
       "├─BatchNorm2d: 1-2                            [1, 32, 140, 140]         64\n",
       "├─ReLU6: 1-3                                  [1, 32, 140, 140]         --\n",
       "├─Sequential: 1-4                             [1, 448, 9, 9]            --\n",
       "│    └─Sequential: 2-1                        [1, 24, 140, 140]         1,168\n",
       "│    └─Sequential: 2-2                        [1, 32, 70, 70]           54,544\n",
       "│    └─Sequential: 2-3                        [1, 56, 35, 35]           165,040\n",
       "│    └─Sequential: 2-4                        [1, 112, 18, 18]          858,480\n",
       "│    └─Sequential: 2-5                        [1, 160, 18, 18]          1,879,392\n",
       "│    └─Sequential: 2-6                        [1, 272, 9, 9]            6,992,864\n",
       "│    └─Sequential: 2-7                        [1, 448, 9, 9]            1,197,152\n",
       "├─Conv2d: 1-5                                 [1, 1280, 9, 9]           573,440\n",
       "├─BatchNorm2d: 1-6                            [1, 1280, 9, 9]           2,560\n",
       "├─ReLU6: 1-7                                  [1, 1280, 9, 9]           --\n",
       "├─SelectAdaptivePool2d: 1-8                   [1, 1280]                 --\n",
       "│    └─AdaptiveAvgPool2d: 2-8                 [1, 1280, 1, 1]           --\n",
       "│    └─Flatten: 2-9                           [1, 1280]                 --\n",
       "├─Linear: 1-9                                 [1, 1000]                 1,281,000\n",
       "===============================================================================================\n",
       "Total params: 13,006,568\n",
       "Trainable params: 13,006,568\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 2.19\n",
       "===============================================================================================\n",
       "Input size (MB): 0.94\n",
       "Forward/backward pass size (MB): 400.60\n",
       "Params size (MB): 52.03\n",
       "Estimated Total Size (MB): 453.57\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(m, (1, 3, img_sizes[4-1], img_sizes[4-1]), depth=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0261c6-469a-4a90-ad3e-f8cddf440767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
